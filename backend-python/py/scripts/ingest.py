import os
import glob
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from dotenv import load_dotenv

# ì„¤ì • (ì ˆëŒ€ ê²½ë¡œë¡œ í†µí•©)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(BASE_DIR, "data")
DB_PATH = os.path.join(BASE_DIR, "backend", "chroma_db")
EMBEDDING_MODEL = "text-embedding-3-small"

# .env íŒŒì¼ ë¡œë“œ (backend í´ë”ì˜ .env íŒŒì¼ì„ ì ˆëŒ€ ê²½ë¡œë¡œ ì§€ì •)
load_dotenv(os.path.join(BASE_DIR, "backend", ".env"))

def ingest_data():
    print(f"Loading data from {DATA_DIR}...")
    
    # 1. ë°ì´í„° ë¡œë“œ (ëª¨ë“  .txt íŒŒì¼ ì½ê¸°)
    documents = []
    # ë°ì´í„° í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„± ì•ˆë‚´
    if not os.path.exists(DATA_DIR):
        os.makedirs(DATA_DIR)
        print(f"Created {DATA_DIR}. Please put your .txt guideline files there.")
        return

    files = glob.glob(os.path.join(DATA_DIR, "*.txt"))
    if not files:
        print("No .txt files found in ./data folder.")
        print("Please add files like 'police_guide.txt' or 'kisa_manual.txt'.")
        return

    for file_path in files:
        try:
            loader = TextLoader(file_path, encoding='utf-8')
            docs = loader.load()
            # íŒŒì¼ëª…ì„ ë©”íƒ€ë°ì´í„° sourceë¡œ ì €ì¥
            for doc in docs:
                doc.metadata["source"] = os.path.basename(file_path)
            documents.extend(docs)
            print(f"Loaded: {file_path}")
        except Exception as e:
            print(f"Error loading {file_path}: {e}")

    # 2. í…ìŠ¤íŠ¸ ë¶„í•  (Chunking)
    # ê°€ì´ë“œë¼ì¸ì€ ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ì˜ë¯¸ê°€ ìˆìœ¼ë¯€ë¡œ ì ì ˆíˆ ìë¦…ë‹ˆë‹¤.
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50,
        separators=["\n\n", "\n", " ", ""]
    )
    chunks = text_splitter.split_documents(documents)
    print(f"Split into {len(chunks)} chunks.")

    # 3. ì„ë² ë”© ë° ì €ì¥
    print("Embedding and storing in ChromaDB...")
    embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)
    
    # DB ìƒì„± ë° ì €ì¥
    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=DB_PATH,
        collection_name="phishing_guidelines"
    )
    
    # persist()ëŠ” ìµœì‹  ë²„ì „ì—ì„œëŠ” ìë™ ì €ì¥ë˜ì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ í˜¸ì¶œ ê°€ëŠ¥
    # vectorstore.persist() 
    print(f"Successfully saved to {DB_PATH}")

if __name__ == "__main__":
    # ì´ ë¸”ë¡ì€ 'ë°ì´í„° ê´€ë¦¬ ë„êµ¬(Ingest)'ë¥¼ ì‹¤í–‰í•˜ëŠ” ì§„ì…ì ì…ë‹ˆë‹¤.
    # ìƒˆë¡œìš´ ê°€ì´ë“œë¼ì¸ íŒŒì¼ì´ ì¶”ê°€ë˜ì—ˆì„ ë•Œ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
    print("\n" + "="*50)
    print("ğŸ§¹ [Maintenance] Running Data Ingestion Tool...")
    print("="*50)
    ingest_data()
    print("="*50 + "\n")
